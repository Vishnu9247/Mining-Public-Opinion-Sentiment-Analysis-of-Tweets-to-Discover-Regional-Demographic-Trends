{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ecda310",
   "metadata": {},
   "source": [
    "## Sentiment analysis models (Machine Learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2a2162",
   "metadata": {},
   "source": [
    "### Importing all the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "053078d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import gensim.downloader as api\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fb8daf",
   "metadata": {},
   "source": [
    "### Loading the data from csv file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "642cf979",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"tweet_sentiment.csv\")\n",
    "data[\"cleaned_text\"] = data[\"cleaned_text\"].fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573bd6a5",
   "metadata": {},
   "source": [
    "### Converting the text data into TF-IDF and Bag of Words vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee5449cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF shape: (4869, 5000)\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "tfidf_vectors = tfidf_vectorizer.fit_transform(data['cleaned_text'])\n",
    "\n",
    "print(\"TF-IDF shape:\", tfidf_vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5713dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW shape: (4869, 5000)\n"
     ]
    }
   ],
   "source": [
    "bow_vectorizer = CountVectorizer(max_features=5000)\n",
    "bow_vectors = bow_vectorizer.fit_transform(data['cleaned_text'])\n",
    "\n",
    "print(\"BoW shape:\", bow_vectors.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3acb274e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfidf = tfidf_vectors.toarray()\n",
    "X_bow = bow_vectors.toarray()\n",
    "\n",
    "y = data['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f826a5",
   "metadata": {},
   "source": [
    "### Creating training, validation and test sets for model development and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f064ca4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_trainval_tfidf, X_test_tfidf, y_trainval_tfidf, y_test_tfidf = train_test_split(X_tfidf, y, test_size=0.2, stratify=y, random_state=2025)\n",
    "X_train_tfidf, X_val_tfidf, y_train_tfidf, y_val_tfidf = train_test_split(X_trainval_tfidf, y_trainval_tfidf, test_size=0.2, stratify=y_trainval_tfidf, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25e6905d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainval_bow, X_test_bow, y_trainval_bow, y_test_bow = train_test_split(X_bow, y, test_size=0.2, stratify=y, random_state=2025)\n",
    "X_train_bow, X_val_bow, y_train_bow, y_val_bow = train_test_split(X_trainval_bow, y_trainval_bow, test_size=0.2, stratify=y_trainval_bow, random_state=2025)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d60e93",
   "metadata": {},
   "source": [
    "## Building the models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ad010f",
   "metadata": {},
   "source": [
    "SVM model for TF-IDF vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c3520d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best SVM Model Validation F1: 0.6409101137431773\n",
      "SVM Test Results:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.68      0.57      0.62       291\n",
      "           0       0.56      0.66      0.60       354\n",
      "           1       0.69      0.66      0.67       329\n",
      "\n",
      "    accuracy                           0.63       974\n",
      "   macro avg       0.64      0.63      0.63       974\n",
      "weighted avg       0.64      0.63      0.63       974\n",
      "\n",
      "{'C': 10, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': -1, 'probability': False, 'random_state': None, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n"
     ]
    }
   ],
   "source": [
    "svm_params = [\n",
    "    {'C': 1, 'kernel': 'linear', 'gamma': 'scale'},\n",
    "    {'C': 10, 'kernel': 'rbf', 'gamma': 'scale'},\n",
    "    {'C': 0.1, 'kernel': 'linear', 'gamma': 'auto'}\n",
    "]\n",
    "\n",
    "best_svm1 = None\n",
    "best_f1_svm1 = 0\n",
    "\n",
    "for params in svm_params:\n",
    "    model = SVC(**params)\n",
    "    model.fit(X_train_tfidf, y_train_tfidf)\n",
    "    preds = model.predict(X_val_tfidf)\n",
    "    score = f1_score(y_val_tfidf, preds, average='weighted')\n",
    "    if score > best_f1_svm1:\n",
    "        best_f1_svm1 = score\n",
    "        best_svm1 = model\n",
    "\n",
    "print(\"Best SVM Model Validation F1:\", best_f1_svm1)\n",
    "print(\"SVM Test Results:\\n\", classification_report(y_test_tfidf, best_svm1.predict(X_test_tfidf)))\n",
    "print(best_svm1.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd86993c",
   "metadata": {},
   "source": [
    "SVM model for BOW vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73f1d25b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best SVM Model Validation F1: 0.6392189044527785\n",
      "SVM Test Results:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.61      0.56      0.59       291\n",
      "           0       0.56      0.63      0.59       354\n",
      "           1       0.68      0.64      0.66       329\n",
      "\n",
      "    accuracy                           0.61       974\n",
      "   macro avg       0.62      0.61      0.61       974\n",
      "weighted avg       0.62      0.61      0.62       974\n",
      "\n",
      "{'C': 10, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': -1, 'probability': False, 'random_state': None, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n"
     ]
    }
   ],
   "source": [
    "best_svm2 = None\n",
    "best_f1_svm2 = 0\n",
    "\n",
    "for params in svm_params:\n",
    "    model = SVC(**params)\n",
    "    model.fit(X_train_bow, y_train_bow)\n",
    "    preds = model.predict(X_val_bow)\n",
    "    score = f1_score(y_val_bow, preds, average='weighted')\n",
    "    if score > best_f1_svm2:\n",
    "        best_f1_svm2 = score\n",
    "        best_svm2 = model\n",
    "\n",
    "print(\"Best SVM Model Validation F1:\", best_f1_svm2)\n",
    "print(\"SVM Test Results:\\n\", classification_report(y_test_bow, best_svm2.predict(X_test_bow)))\n",
    "print(best_svm2.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe16bdc",
   "metadata": {},
   "source": [
    "Naive Bayes model for TF-IDF vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b9fe5d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best NB Validation F1: 0.6202973310687443\n",
      "Naive Bayes Test Results:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.67      0.49      0.57       291\n",
      "           0       0.55      0.64      0.59       354\n",
      "           1       0.63      0.67      0.65       329\n",
      "\n",
      "    accuracy                           0.61       974\n",
      "   macro avg       0.62      0.60      0.61       974\n",
      "weighted avg       0.62      0.61      0.61       974\n",
      "\n",
      "{'alpha': 0.5, 'class_prior': None, 'fit_prior': True, 'force_alpha': 'warn'}\n"
     ]
    }
   ],
   "source": [
    "nb_params = [0.1, 0.5, 1.0]\n",
    "best_nb1 = None\n",
    "best_f1_nb1 = 0\n",
    "\n",
    "for alpha in nb_params:\n",
    "    model = MultinomialNB(alpha=alpha)\n",
    "    model.fit(X_train_tfidf, y_train_tfidf)\n",
    "    preds = model.predict(X_val_tfidf)\n",
    "    score = f1_score(y_val_tfidf, preds, average='weighted')\n",
    "    if score > best_f1_nb1:\n",
    "        best_f1_nb1 = score\n",
    "        best_nb1 = model\n",
    "\n",
    "print(\"Best NB Validation F1:\", best_f1_nb1)\n",
    "print(\"Naive Bayes Test Results:\\n\", classification_report(y_test_tfidf, best_nb1.predict(X_test_tfidf)))\n",
    "print(best_nb1.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97b29e8",
   "metadata": {},
   "source": [
    "Naive Bayes model for BOW vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e20335c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best NB Validation F1: 0.6320292029485731\n",
      "Naive Bayes Test Results:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.65      0.56      0.60       291\n",
      "           0       0.56      0.60      0.58       354\n",
      "           1       0.66      0.69      0.67       329\n",
      "\n",
      "    accuracy                           0.62       974\n",
      "   macro avg       0.63      0.62      0.62       974\n",
      "weighted avg       0.62      0.62      0.62       974\n",
      "\n",
      "{'alpha': 1.0, 'class_prior': None, 'fit_prior': True, 'force_alpha': 'warn'}\n"
     ]
    }
   ],
   "source": [
    "nb_params = [0.1, 0.5, 1.0]\n",
    "best_nb2 = None\n",
    "best_f1_nb2 = 0\n",
    "\n",
    "for alpha in nb_params:\n",
    "    model = MultinomialNB(alpha=alpha)\n",
    "    model.fit(X_train_bow, y_train_bow)\n",
    "    preds = model.predict(X_val_bow)\n",
    "    score = f1_score(y_val_bow, preds, average='weighted')\n",
    "    if score > best_f1_nb2:\n",
    "        best_f1_nb2 = score\n",
    "        best_nb2 = model\n",
    "\n",
    "print(\"Best NB Validation F1:\", best_f1_nb2)\n",
    "print(\"Naive Bayes Test Results:\\n\", classification_report(y_test_bow, best_nb2.predict(X_test_bow)))\n",
    "print(best_nb2.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd682f22",
   "metadata": {},
   "source": [
    "Random Forest for TF-IDF vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66c9362d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RF Validation F1: 0.6236110243366157\n",
      "Random Forest Test Results:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.75      0.43      0.55       291\n",
      "           0       0.52      0.79      0.62       354\n",
      "           1       0.74      0.60      0.67       329\n",
      "\n",
      "    accuracy                           0.62       974\n",
      "   macro avg       0.67      0.61      0.61       974\n",
      "weighted avg       0.66      0.62      0.61       974\n",
      "\n",
      "{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': 2025, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "rf_params = [\n",
    "    {'n_estimators': 100, 'max_depth': None},\n",
    "    {'n_estimators': 200, 'max_depth': 10},\n",
    "    {'n_estimators': 100, 'max_depth': 20}\n",
    "]\n",
    "\n",
    "best_rf1 = None\n",
    "best_f1_rf1 = 0\n",
    "\n",
    "for params in rf_params:\n",
    "    model = RandomForestClassifier(random_state=2025, **params)\n",
    "    model.fit(X_train_tfidf, y_train_tfidf)\n",
    "    preds = model.predict(X_val_tfidf)\n",
    "    score = f1_score(y_val_tfidf, preds, average='weighted')\n",
    "    if score > best_f1_rf1:\n",
    "        best_f1_rf1 = score\n",
    "        best_rf1 = model\n",
    "\n",
    "print(\"Best RF Validation F1:\", best_f1_rf1)\n",
    "print(\"Random Forest Test Results:\\n\", classification_report(y_test_tfidf, best_rf1.predict(X_test_tfidf)))\n",
    "print(best_rf1.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5362edaf",
   "metadata": {},
   "source": [
    "Random Forest for BOW vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6a69943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RF Validation F1: 0.6437552550750975\n",
      "Random Forest Test Results:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.73      0.49      0.59       291\n",
      "           0       0.52      0.72      0.60       354\n",
      "           1       0.71      0.63      0.67       329\n",
      "\n",
      "    accuracy                           0.62       974\n",
      "   macro avg       0.66      0.61      0.62       974\n",
      "weighted avg       0.65      0.62      0.62       974\n",
      "\n",
      "{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': 2025, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "rf_params = [\n",
    "    {'n_estimators': 100, 'max_depth': None},\n",
    "    {'n_estimators': 200, 'max_depth': 10},\n",
    "    {'n_estimators': 100, 'max_depth': 20}\n",
    "]\n",
    "\n",
    "best_rf2 = None\n",
    "best_f1_rf2 = 0\n",
    "\n",
    "for params in rf_params:\n",
    "    model = RandomForestClassifier(random_state=2025, **params)\n",
    "    model.fit(X_train_bow, y_train_bow)\n",
    "    preds = model.predict(X_val_bow)\n",
    "    score = f1_score(y_val_bow, preds, average='weighted')\n",
    "    if score > best_f1_rf2:\n",
    "        best_f1_rf2 = score\n",
    "        best_rf2 = model\n",
    "\n",
    "print(\"Best RF Validation F1:\", best_f1_rf2)\n",
    "print(\"Random Forest Test Results:\\n\", classification_report(y_test_bow, best_rf2.predict(X_test_bow)))\n",
    "print(best_rf2.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6236f463",
   "metadata": {},
   "source": [
    "### Creating a function to create results for a summary table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4586ea00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(y_true, y_pred, model_name):\n",
    "    return {\n",
    "        'Model': model_name,\n",
    "        'Accuracy': accuracy_score(y_true, y_pred),\n",
    "        'Precision': precision_score(y_true, y_pred, average='weighted'),\n",
    "        'Recall': recall_score(y_true, y_pred, average='weighted'),\n",
    "        'F1 Score': f1_score(y_true, y_pred, average='weighted')\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad81c349",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_pred1 = best_svm1.predict(X_test_tfidf)\n",
    "rf_pred1 = best_rf1.predict(X_test_tfidf)\n",
    "nb_pred1 = best_nb1.predict(X_test_tfidf)\n",
    "\n",
    "svm_pred2 = best_svm2.predict(X_test_bow)\n",
    "rf_pred2 = best_rf2.predict(X_test_bow)\n",
    "nb_pred2 = best_nb2.predict(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2cc6226e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [\n",
    "    get_metrics(y_test_tfidf, svm_pred1, \"SVM with TF-IDF\"),\n",
    "    get_metrics(y_test_tfidf, rf_pred1, \"Random Forest with TF-IDF\"),\n",
    "    get_metrics(y_test_tfidf, nb_pred1, \"Naive Bayes with TF-IDF\"),\n",
    "    get_metrics(y_test_bow, svm_pred2, \"SVM with BOW\"),\n",
    "    get_metrics(y_test_bow, rf_pred2, \"Random Forest with BOW\"),\n",
    "    get_metrics(y_test_bow, nb_pred2, \"Naive Bayes with BOW\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cab56706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM with TF-IDF</td>\n",
       "      <td>0.631417</td>\n",
       "      <td>0.640146</td>\n",
       "      <td>0.631417</td>\n",
       "      <td>0.632379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest with TF-IDF</td>\n",
       "      <td>0.618070</td>\n",
       "      <td>0.661901</td>\n",
       "      <td>0.618070</td>\n",
       "      <td>0.614562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive Bayes with TF-IDF</td>\n",
       "      <td>0.607803</td>\n",
       "      <td>0.616069</td>\n",
       "      <td>0.607803</td>\n",
       "      <td>0.606162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM with BOW</td>\n",
       "      <td>0.614990</td>\n",
       "      <td>0.618498</td>\n",
       "      <td>0.614990</td>\n",
       "      <td>0.615568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest with BOW</td>\n",
       "      <td>0.621150</td>\n",
       "      <td>0.649708</td>\n",
       "      <td>0.621150</td>\n",
       "      <td>0.621738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Naive Bayes with BOW</td>\n",
       "      <td>0.620123</td>\n",
       "      <td>0.622373</td>\n",
       "      <td>0.620123</td>\n",
       "      <td>0.619829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model  Accuracy  Precision    Recall  F1 Score\n",
       "0            SVM with TF-IDF  0.631417   0.640146  0.631417  0.632379\n",
       "1  Random Forest with TF-IDF  0.618070   0.661901  0.618070  0.614562\n",
       "2    Naive Bayes with TF-IDF  0.607803   0.616069  0.607803  0.606162\n",
       "3               SVM with BOW  0.614990   0.618498  0.614990  0.615568\n",
       "4     Random Forest with BOW  0.621150   0.649708  0.621150  0.621738\n",
       "5       Naive Bayes with BOW  0.620123   0.622373  0.620123  0.619829"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324821c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
